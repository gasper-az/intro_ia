{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3294318e",
   "metadata": {},
   "source": [
    "# TP3: Detector de SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865e657",
   "metadata": {},
   "source": [
    "## Integrantes\n",
    "\n",
    "- Nicolás Rodriguez da Cruz\n",
    "- Francisco Cofré\n",
    "- Gaspar Acevedo Zain\n",
    "- Juan Chunga\n",
    "- Rodrigo Nicolás Lauro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f193af5",
   "metadata": {},
   "source": [
    "### Imports y carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5a8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scikit-learn ofrece una variedad de modelos Naive Bayes. Para este problema, utilizamos MultinomialNB, que es adecuado para datos de conteo como este.\n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345cc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/spambase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e472a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>104.553358</td>\n",
       "      <td>213.014345</td>\n",
       "      <td>280.656379</td>\n",
       "      <td>65.424908</td>\n",
       "      <td>312.222995</td>\n",
       "      <td>95.900891</td>\n",
       "      <td>114.207564</td>\n",
       "      <td>105.294501</td>\n",
       "      <td>90.067377</td>\n",
       "      <td>239.413171</td>\n",
       "      <td>...</td>\n",
       "      <td>179.823734</td>\n",
       "      <td>5.444469</td>\n",
       "      <td>31.869159</td>\n",
       "      <td>38.574440</td>\n",
       "      <td>139.030428</td>\n",
       "      <td>16.975875</td>\n",
       "      <td>269.068898</td>\n",
       "      <td>75.810259</td>\n",
       "      <td>44.237992</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>305.357562</td>\n",
       "      <td>1290.574888</td>\n",
       "      <td>504.142884</td>\n",
       "      <td>1395.151370</td>\n",
       "      <td>672.511666</td>\n",
       "      <td>273.824083</td>\n",
       "      <td>391.440302</td>\n",
       "      <td>401.071452</td>\n",
       "      <td>278.615864</td>\n",
       "      <td>644.755399</td>\n",
       "      <td>...</td>\n",
       "      <td>911.118627</td>\n",
       "      <td>76.274271</td>\n",
       "      <td>285.734646</td>\n",
       "      <td>243.470469</td>\n",
       "      <td>270.355374</td>\n",
       "      <td>109.394164</td>\n",
       "      <td>815.669848</td>\n",
       "      <td>245.879440</td>\n",
       "      <td>429.341596</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4540.000000</td>\n",
       "      <td>14280.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>42810.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>5880.000000</td>\n",
       "      <td>7270.000000</td>\n",
       "      <td>11110.000000</td>\n",
       "      <td>5260.000000</td>\n",
       "      <td>18180.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22050.000000</td>\n",
       "      <td>2170.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>4385.000000</td>\n",
       "      <td>9752.000000</td>\n",
       "      <td>4081.000000</td>\n",
       "      <td>32478.000000</td>\n",
       "      <td>6003.000000</td>\n",
       "      <td>19829.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean       104.553358         213.014345     280.656379     65.424908   \n",
       "std        305.357562        1290.574888     504.142884   1395.151370   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000     420.000000      0.000000   \n",
       "max       4540.000000       14280.000000    5100.000000  42810.000000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean      312.222995       95.900891        114.207564          105.294501   \n",
       "std       672.511666      273.824083        391.440302          401.071452   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%       380.000000        0.000000          0.000000            0.000000   \n",
       "max     10000.000000     5880.000000       7270.000000        11110.000000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_edu  word_freq_table  \\\n",
       "count      4601.000000     4601.000000  ...    4601.000000      4601.000000   \n",
       "mean         90.067377      239.413171  ...     179.823734         5.444469   \n",
       "std         278.615864      644.755399  ...     911.118627        76.274271   \n",
       "min           0.000000        0.000000  ...       0.000000         0.000000   \n",
       "25%           0.000000        0.000000  ...       0.000000         0.000000   \n",
       "50%           0.000000        0.000000  ...       0.000000         0.000000   \n",
       "75%           0.000000      160.000000  ...       0.000000         0.000000   \n",
       "max        5260.000000    18180.000000  ...   22050.000000      2170.000000   \n",
       "\n",
       "       word_freq_conference  char_freq_;  char_freq_(  char_freq_[  \\\n",
       "count           4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean              31.869159    38.574440   139.030428    16.975875   \n",
       "std              285.734646   243.470469   270.355374   109.394164   \n",
       "min                0.000000     0.000000     0.000000     0.000000   \n",
       "25%                0.000000     0.000000     0.000000     0.000000   \n",
       "50%                0.000000     0.000000    65.000000     0.000000   \n",
       "75%                0.000000     0.000000   188.000000     0.000000   \n",
       "max            10000.000000  4385.000000  9752.000000  4081.000000   \n",
       "\n",
       "        char_freq_!  char_freq_$   char_freq_#         spam  \n",
       "count   4601.000000  4601.000000   4601.000000  4601.000000  \n",
       "mean     269.068898    75.810259     44.237992     0.394045  \n",
       "std      815.669848   245.879440    429.341596     0.488698  \n",
       "min        0.000000     0.000000      0.000000     0.000000  \n",
       "25%        0.000000     0.000000      0.000000     0.000000  \n",
       "50%        0.000000     0.000000      0.000000     0.000000  \n",
       "75%      315.000000    52.000000      0.000000     1.000000  \n",
       "max    32478.000000  6003.000000  19829.000000     1.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30260e12",
   "metadata": {},
   "source": [
    "### 1. ¿Cuáles son las 10 palabras o símbolos más frecuentes en correos SPAM y en correos NO SPAM?\n",
    "\n",
    "1. ¿Hay palabras o símbolos en común?\n",
    "1. ¿Alguna resulta llamativa?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7030a3b",
   "metadata": {},
   "source": [
    "#### Resolución\n",
    "\n",
    "*10 palabras más repetidas en correos **NO spam***\n",
    "| Palabra | Frecuencia |\n",
    "| --- | --- |\n",
    "| you | $3541702$ |\n",
    "| george | $3527559$ |\n",
    "| hp | $2496576$|\n",
    "| will | $1495268$ |\n",
    "| your | $1223098$ |\n",
    "| hpl | $1204398$ |\n",
    "| re | $1159138$ |\n",
    "| edu | $800669$ |\n",
    "| address | $681569$ |\n",
    "| meeting | $604460$ |\n",
    "\n",
    "*10 palabras más repetidas en correos **spam***\n",
    "| Palabra | Frecuencia |\n",
    "| --- | --- |\n",
    "| you | $4105599$ |\n",
    "| your | $2502597$ |\n",
    "| will | $997100$ |\n",
    "| free | $939790$ |\n",
    "| our | $931799$ |\n",
    "| ! | $931352$ |\n",
    "| all | $732080$ |\n",
    "| mail | $635470$ |\n",
    "| email | $578759$ |\n",
    "| business | $52125$ |\n",
    "\n",
    "##### 1.1 ¿Hay palabras o símbolos en común?\n",
    "\n",
    "Si, entre las diez palabras/símbolos más frecuentes en correos marcados como Spam y NO Spam hay tres palabras repetidas:\n",
    "\n",
    "| Palabra | Frecuencia NO Spam | Frecuencia Spam |\n",
    "| --- | --- | --- |\n",
    "| you | $3541702$ | $4105599$ |\n",
    "| your | $1223098$ | $2502597$ |\n",
    "| will | $1495268$ | $997100$ |\n",
    "\n",
    "Como se puede observar, la palabra `you` aparece $3.541.702$ de veces en correos NO Spam, pero se repite más veces en correos Spam, con un total de $4.105.599$.\n",
    "Con la palabra `your` sucede algo similar: aparece $1.223.098$ veces en correos No Spam, pero en correos Spam la cantidad de veces es mayor, con un total de $2.502.597$.\n",
    "Por último, la palabra `will` aparece más veces en correos No Spam: $1.495.268$, contra $997.100$ veces en correos Spam.\n",
    "\n",
    "##### 1.2 ¿Alguna resulta llamativa?\n",
    "\n",
    "Las que nos resultan llamativas de correos NO Spam son las palabras `hp` (aparece $2.496.576$), `hpl` ($1.204.398$), y `re` ($1.159.138$). Si bien, desconocemos el significado de las dos primeras, la tercer palabra (`re`) puede referirse al termino que aparece cuando el email es una respuesta o *reply* de una cadena de mensajes.\n",
    "\n",
    "En cuanto a las palabras y símbolos llamativos de correos Spam, notamos que la palabra `free` (gratis en inglés) aparece $939.790$ de veces, mientras que el símbolo de explamación `!` aparece $931.352$ de veces. Esto puede deberse a que son palabras/símbolos utilizados para llamar la atención del receptor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b267b",
   "metadata": {},
   "source": [
    "#### Código para la resolución del punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59773255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, agrupamos por la columna \"spam\" y sumamos la cantidad de datos para cada columna\n",
    "spam_col = \"spam\"\n",
    "group_by = dataset.groupby(by=spam_col, as_index=False).sum()\n",
    "\n",
    "# Subdividimos en Spam y No Spam, para facilitar el análisis\n",
    "group_by_no_spam = group_by[group_by[spam_col]==0]\n",
    "group_by_spam = group_by[group_by[spam_col]==1]\n",
    "\n",
    "# Usando pandas.melt (https://pandas.pydata.org/docs/reference/api/pandas.melt.html), hacemos un pivot, y luego ordenamos por la columna \"Values\" de manera descendente\n",
    "# NOTE: hacemos drop de la columna \"spam\" para que no aparezca entre los resultados\n",
    "value_col = \"value\"\n",
    "spam_ordered = pd.melt(group_by_spam.drop(columns=spam_col)).sort_values(by=value_col, ascending=False)\n",
    "no_spam_ordered = pd.melt(group_by_no_spam.drop(columns=spam_col)).sort_values(by=value_col, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea0da2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos la cantidad de símbolos a mostrar\n",
    "simbols_to_show = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec92c11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>word_freq_you</td>\n",
       "      <td>3541702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>word_freq_george</td>\n",
       "      <td>3527559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>word_freq_hp</td>\n",
       "      <td>2496576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>word_freq_will</td>\n",
       "      <td>1495268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_freq_your</td>\n",
       "      <td>1223098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>word_freq_hpl</td>\n",
       "      <td>1204398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>word_freq_re</td>\n",
       "      <td>1159138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>word_freq_edu</td>\n",
       "      <td>800669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_freq_address</td>\n",
       "      <td>681569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>word_freq_meeting</td>\n",
       "      <td>604460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable    value\n",
       "18      word_freq_you  3541702\n",
       "26   word_freq_george  3527559\n",
       "24       word_freq_hp  2496576\n",
       "11     word_freq_will  1495268\n",
       "20     word_freq_your  1223098\n",
       "25      word_freq_hpl  1204398\n",
       "44       word_freq_re  1159138\n",
       "45      word_freq_edu   800669\n",
       "1   word_freq_address   681569\n",
       "41  word_freq_meeting   604460"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_spam_ordered.head(n=simbols_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d625b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>word_freq_you</td>\n",
       "      <td>4105599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_freq_your</td>\n",
       "      <td>2502597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>word_freq_will</td>\n",
       "      <td>997100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>word_freq_free</td>\n",
       "      <td>939790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_freq_our</td>\n",
       "      <td>931799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>char_freq_!</td>\n",
       "      <td>931352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_freq_all</td>\n",
       "      <td>732080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>word_freq_mail</td>\n",
       "      <td>635470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>word_freq_email</td>\n",
       "      <td>578759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>word_freq_business</td>\n",
       "      <td>521250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              variable    value\n",
       "18       word_freq_you  4105599\n",
       "20      word_freq_your  2502597\n",
       "11      word_freq_will   997100\n",
       "15      word_freq_free   939790\n",
       "4        word_freq_our   931799\n",
       "51         char_freq_!   931352\n",
       "2        word_freq_all   732080\n",
       "9       word_freq_mail   635470\n",
       "17     word_freq_email   578759\n",
       "16  word_freq_business   521250"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_ordered.head(n=simbols_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e336d2",
   "metadata": {},
   "source": [
    "### 2. Separe el conjunto de datos en un conjunto de entrenamiento (70%) y uno de prueba (30%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fc9040",
   "metadata": {},
   "source": [
    "#### Resolución\n",
    "\n",
    "Antes de hacer la división en conjuntos de entrenamiento y prueba con valores 70%-30% respectivamente, debemos analizar si nuestra variable objetivo `Spam` está balanceada.\n",
    "Luego de analizar la cantidad de correos maracados como Spam o No Spam, encontramos que no están balanceados, ya que hay $1813$ Spam y $2788$ No Spam.\n",
    "\n",
    "Por eso, al realizar la división en train-test, debemos utilizar el parámetro [stratify](https://scikit-learn.org/stable/modules/cross_validation.html#stratification) de la funcion [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "De esta manera, obtenemos:\n",
    "- `Conjunto de entrenamiento`: 1269 Spam y 1951 No Spam\n",
    "- `Conjunto de prueba`: 544 Spam y 837 No Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c11b4",
   "metadata": {},
   "source": [
    "#### Código para la resolución del punto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab41c9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de correos marcados como SPAM: 1813\n",
      "Cantidad de correos marcados como No SPAM: 2788\n"
     ]
    }
   ],
   "source": [
    "# Primero, obtenemos la cantidad de registros marcados como Spam y NO Spam, para determinar si las clases están balanceadas\n",
    "no_spam_data = dataset[dataset[spam_col]==0]\n",
    "spam_data = dataset[dataset[spam_col]==1]\n",
    "\n",
    "print(f\"Cantidad de correos marcados como SPAM: {len(spam_data)}\")\n",
    "print(f\"Cantidad de correos marcados como No SPAM: {len(no_spam_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a39bc921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a que las clases están desbalanceadas (1813 SPAM y 2788 No SPAM), al dividir en Train y Test debemos hacer un stratify\n",
    "\n",
    "X = dataset.drop(columns=spam_col)\n",
    "y = dataset[spam_col]\n",
    "\n",
    "random_state = 100019\n",
    "test_size = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a25bcc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de correos SPAM en train: 1269\n",
      "Cantidad de correos No SPAM en train: 1951\n",
      "Cantidad de correos SPAM en test: 544\n",
      "Cantidad de correos No SPAM en test: 837\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de correos SPAM en train: {len(y_train[y_train==1])}\")\n",
    "print(f\"Cantidad de correos No SPAM en train: {len(y_train[y_train==0])}\")\n",
    "\n",
    "print(f\"Cantidad de correos SPAM en test: {len(y_test[y_test==1])}\")\n",
    "print(f\"Cantidad de correos No SPAM en test: {len(y_test[y_test==0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312db254",
   "metadata": {},
   "source": [
    "### 3. Utilizando un **clasificador de Bayes ingenuo**, entrene el modelo con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0a0c7",
   "metadata": {},
   "source": [
    "### 4. Utilizando un **clasificador de Regresión Logística**, entrene el modelo con el conjunto de entrenamiento (en este caso, normalice los datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84075d4",
   "metadata": {},
   "source": [
    "### 5. Calcule la **matriz de confusión** en el conjunto de prueba para ambos modelos.\n",
    "\n",
    "1. ¿Qué tipo de error comete más cada modelo?\n",
    "1. ¿Cuál de los dos tipos de error considera más importante en este problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eaeb58",
   "metadata": {},
   "source": [
    "### 6. Calcule las **métricas de precisión (precision) y recuperación (recall)** para ambos modelos.\n",
    "\n",
    "1. ¿Cuál es el mejor modelo según cada métrica?\n",
    "1. ¿Cómo se relacionan estas métricas con los errores analizados en el punto anterior? Fundamente su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c06ff8",
   "metadata": {},
   "source": [
    "### 7. Obtenga la **curva ROC y el AUC (Área Bajo la Curva ROC)** de ambos modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_env_3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
